{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4976281",
   "metadata": {},
   "source": [
    "# Process Images with scPortrait to generate single-cell image datasets\n",
    "\n",
    "In this notebook we are going to process the previously uploaded images with the [scPortrait](https://github.com/MannLabs/scPortrait) library to generate single-cell images we can use to asses autophagosome formation at a single-cell level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c3ad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lamindb as ln\n",
    "import os\n",
    "import h5py\n",
    "from scportrait.pipeline.extraction import HDF5CellExtraction\n",
    "from scportrait.pipeline.project import Project\n",
    "from scportrait.pipeline.segmentation.workflows import CytosolSegmentationCellpose\n",
    "\n",
    "ln.track()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d9eabd",
   "metadata": {},
   "source": [
    "First lets find all of the images we want to process in our lamindb instance. To do this we are going to use a query call to get all artifacts that belong to our study name and that are tagged with the label \"input images\". This will ensure that as soon as we have also saved intermediate results into our lamindb instance our code will still work and we will only process the input tif files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04595f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all input data that is to be processed\n",
    "study = ln.ULabel.get(name=\"autophagy imaging\")\n",
    "input_images = ln.ULabel.get(name=\"input images\")\n",
    "\n",
    "input_images = ln.Artifact.filter(ulabels = study).filter(ulabels = input_images).filter(suffix = \".tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903bfd59",
   "metadata": {},
   "source": [
    "Now we know that in our experiment we have imaged different genotypes (WT and EI24KO), that were treated differently (unstimulated vs 14h Torin-1). For each condition we had multiple clonal cell lines and imaged multiple FOVs in all of the imaging channels. To properly process this dataset we will need to get single-cell images from each FOV indivdually and tag them with all of the appropriate metadata so that we can identify genotype, treatment condition, clonal cell line and imaging experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c08e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [ln.ULabel.get(name=x) for x in set(a.features.get_values()['stimulation'] for a in input_images)]\n",
    "cell_line_clones = [ln.ULabel.get(name=x) for x in set(a.features.get_values()['cell_line_clone'] for a in input_images)]\n",
    "FOVs = [ln.ULabel.get(name=x) for x in set(a.features.get_values()['FOV'] for a in input_images)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61a250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images[0].features.get_values()\n",
    "\n",
    "#would be nice to be able to do something equivalent to\n",
    "#input_images.features.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7bc0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is not working as expected -> should have a lot more features\n",
    "ln.Artifact.filter(ulabels = study).df(features = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec0dc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c495439a",
   "metadata": {},
   "source": [
    "If we now iterate through conditions, celllines and FOVs and get all the input images assigned to a unique combination of these keys we should only have the images showing a single FOV in the 3 imaged channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af21aaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_channels = 3\n",
    "for condition in conditions:\n",
    "    for cellline in cell_line_clones:\n",
    "        for FOV in FOVs:\n",
    "            images = input_images.filter(ulabels = condition).filter(ulabels = cellline).filter(ulabels = FOV).distinct()\n",
    "            assert len(images) == number_of_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbbdb07",
   "metadata": {},
   "source": [
    "Now that we know which image files belong together we want to process them. To be able to gain biological insight from this data we want to process all of these individual FOVs in a consistent manner.\n",
    "\n",
    "To do that we will first upload our common config file containing the processing parameters to our lamindb instance and then define a transform function to process each FOV individually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e26449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load config file for processing all datasets\n",
    "config_path = ln.Artifact.get(key = \"input_data/config.yml\").load().path\n",
    "config_file = ln.Artifact(config_path, \n",
    "                         description=\"config for scportrait for processing of cells stained for autophagy markers\",\n",
    "                        ).save()\n",
    "\n",
    "#annotate the config file with the metadata relevant to the study\n",
    "config_file.features.add_values(\n",
    "    {\n",
    "        \"study\": \"autophagy imaging\",\n",
    "        \"artefact type\": \"scportrait config\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e56cbf",
   "metadata": {},
   "source": [
    "If we needed to find this config later on in our lamindb instance we could again query for it. Using `.one()` ensures that only 1 artifact exists that matches our filter criteria. If this is not the case an error would be returned which would let us know that we need to refine our search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e236f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the config file we want to use for processing\n",
    "config = ln.ULabel.get(name=\"scportrait config\")\n",
    "config_file = ln.Artifact.filter(ulabels = study).filter(ulabels = config).one()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edb565e",
   "metadata": {},
   "source": [
    "To properly track our inputs and outputs in lamindb so that we later on track data lineages. We will define our custom processing function as a transform and track this transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa015945",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ln.tracked()\n",
    "def _process_images(config_file:ln.Artifact, \n",
    "                    input_artefacts:ln._query_set.QuerySet, \n",
    "                    output_directory:str) -> None:\n",
    "    \n",
    "    #perform quick sanity check that we only have images which share all of their attributed except channel and imaged structure\n",
    "    _features = []\n",
    "    values_to_ignore = [\"channel\", \"imaged structure\"]\n",
    "    \n",
    "    for i in input_artefacts:\n",
    "        features = i.features.get_values()\n",
    "        features = {key: features[key] for key in features.keys() if key not in values_to_ignore}\n",
    "        _features.append(features)\n",
    "    assert all([_features[0] == f for f in _features])\n",
    "    shared_features = _features[0]\n",
    "\n",
    "    #get the paths to the input images\n",
    "    mcherry = input_artefacts.filter(ulabels = ln.ULabel.get(name=\"mCherry\"))\n",
    "    DAPI = input_artefacts.filter(ulabels = ln.ULabel.get(name=\"DAPI\"))\n",
    "    Alexa488 = input_artefacts.filter(ulabels = ln.ULabel.get(name=\"Alexa488\"))\n",
    "\n",
    "    paths = [DAPI.one().load().path, \n",
    "             Alexa488.one().load().path, \n",
    "             mcherry.one().load().path,\n",
    "             ]\n",
    "    \n",
    "    #create a unique identifier for the project based on the annotated features\n",
    "    unique_project_id = f\"{shared_features['cell_line_clone']}/{shared_features['stimulation']}/{shared_features['FOV']}\".replace(\" \", \"_\")\n",
    "    \n",
    "    #create the project location\n",
    "    project_location = f\"{output_directory}/{unique_project_id}/scportrait_project\"\n",
    "    os.makedirs(project_location, exist_ok=True)\n",
    "    \n",
    "    project = Project(project_location=project_location,\n",
    "                        config_path= config_file.load().path, \n",
    "                        segmentation_f= CytosolSegmentationCellpose,\n",
    "                        extraction_f= HDF5CellExtraction, \n",
    "                        overwrite=True\n",
    "                        )\n",
    "\n",
    "    #process the project\n",
    "    project.load_input_from_tif_files(paths, overwrite=True, channel_names=[\"DAPI\",\"Alexa488\",  \"mCherry\"])\n",
    "    project.segment()\n",
    "    project.extract()\n",
    "\n",
    "    #potentially we also want to save additional output here (i.e. generated sdata project structure)\n",
    "    \n",
    "    #save the generated results back to lamindb\n",
    "    single_cell_images = f\"{project_location}/extraction/data/single_cells.h5\"\n",
    "    \n",
    "    #update the annotation to reflect the new data modality\n",
    "    annotation = shared_features\n",
    "    annotation[\"filetype\"] = \"h5\" #update filetype to h5\n",
    "    annotation[\"number of single-cells\"] = h5py.File(single_cell_images, \"r\")[\"single_cell_index\"].shape[0]\n",
    "    annotation[\"channel\"] = [ln.ULabel.get(name=x) for x in [\"DAPI\", \"mCherry\", \"Alexa488\"]]\n",
    "    annotation[\"imaged structure\"] = [ln.ULabel.get(name=x) for x in ['LckLip-mNeon', 'DNA', 'mCherry-LC3B']]\n",
    "    \n",
    "    artifact = ln.Artifact(single_cell_images, \n",
    "                            description=\"single-cell image dataset of cells stained for autophagy markers\",\n",
    "                            )\n",
    "    artifact.save()\n",
    "    artifact.features.add_values(\n",
    "        annotation\n",
    "    )\n",
    "    artifact.labels.add(ln.ULabel.get(name = \"scportrait single-cell images\")) \n",
    "\n",
    "ln.Param(name='output_directory', dtype='str').save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690947e2",
   "metadata": {},
   "source": [
    "Now we still need to create an output directory where we want to locally store our results before they are uploaded to the lamindb instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60768696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and create an output location\n",
    "output_directory = \"processed_data\"\n",
    "os.makedirs(output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f79f982",
   "metadata": {},
   "source": [
    "Now we are ready to process all of our input images and upload the generated single-cell image datasets back to lamin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd47d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for condition in conditions:\n",
    "    for cellline in cell_line_clones:\n",
    "        for FOV in FOVs:\n",
    "            images = input_images.filter(ulabels = condition).filter(ulabels = cellline).filter(ulabels = FOV).distinct()\n",
    "            _process_images(config_file, input_artefacts = images, output_directory=output_directory)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a669c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_artifact = ln.Artifact.filter(ulabels = ln.ULabel.get(name=\"scportrait single-cell images\"))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672a3070",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_artifact.view_lineage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60cded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.finish()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
