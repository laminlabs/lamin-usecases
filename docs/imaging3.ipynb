{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "628e34ce",
   "metadata": {},
   "source": [
    "# Featurize single-cell images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73c8e6e",
   "metadata": {},
   "source": [
    "Here, we use [scPortrait](https://github.com/MannLabs/scPortrait) to extract cell features that characterize both morphological and intensity-based properties of individual cells:\n",
    "\n",
    "- Area of the masks in pixels\n",
    "- Mean intensity of the chosen channel in the regions labelled by each of the masks\n",
    "- Median intensity of the chosen channel in the regions labelled by each of the masks\n",
    "- 75% quantile of the chosen channel in the regions labelled by each of the masks  \n",
    "- 25% quantile of the chosen channel in the regions labelled by each of the masks\n",
    "- Summed intensity of the chosen channel in the regions labelled by each of the masks\n",
    "- Summed intensity of the chosen channel in the region labelled by each of the masks normalized for area\n",
    "\n",
    "These features provide a comprehensive profile for later training machine learning models to identify cell types and states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c20b42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m→\u001b[0m connected lamindb: scportrait/examples\n",
      "\u001b[92m→\u001b[0m loaded Transform('ujI2BcWc8AA60000'), re-started Run('aWmCDdv4...') at 2025-02-24 15:03:20 UTC\n",
      "\u001b[92m→\u001b[0m notebook imports: bionty==1.1.0 lamindb==1.1.0 pandas==2.2.3 scportrait==1.1.1.dev0\n"
     ]
    }
   ],
   "source": [
    "import lamindb as ln\n",
    "import bionty as bt\n",
    "import pandas as pd\n",
    "\n",
    "from scportrait.pipeline.featurization import CellFeaturizer\n",
    "\n",
    "ln.track()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37ce238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get single-cell images and config\n",
    "sc_datasets = ln.Artifact.filter(ulabels__name=\"autophagy imaging\").filter(\n",
    "    ulabels__name=\"scportrait single-cell images\"\n",
    ")\n",
    "config = (\n",
    "    ln.Artifact.filter(ulabels__name=\"autophagy imaging\")\n",
    "    .filter(ulabels__name=\"scportrait config\")\n",
    "    .distinct()\n",
    "    .one()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72cf122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... synchronizing LsozDWhSsP9ajLJL0000.h5: 100.0%\n",
      "... synchronizing DkbGSFdQT3AXjqQt0000.h5: 100.0%\n",
      "... synchronizing Ytx4E35Xfe3ubE190000.h5: 100.0%\n",
      "... synchronizing e1KSk8g7Y1GuxX6S0000.h5: 100.0%\n",
      "... synchronizing hCw1GXdk9tonZ7DG0000.h5: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Process single-cell images with scPortrait's featurizer\n",
    "featurizer = CellFeaturizer(directory=\".\", config=config.cache(), project_location=None)\n",
    "\n",
    "# Train on wildtype (WT) cells\n",
    "wt_cells_afs = sc_datasets.filter(ulabels__name=\"WT\")\n",
    "\n",
    "# we have two different conditions which will be the two classes that our classifier should be able to tell apart\n",
    "condition_uls = [\n",
    "    ln.ULabel.get(name=stim_name)\n",
    "    for stim_name in set(af.features.get_values()[\"stimulation\"] for af in wt_cells_afs)\n",
    "]\n",
    "\n",
    "# Store the calculated features in a dictionary for each condition\n",
    "condition_lookup = {}\n",
    "features = None\n",
    "for idx, condition_ul in enumerate(condition_uls):\n",
    "    cells = wt_cells_afs.filter(ulabels=condition_ul)\n",
    "    paths = [dataset.load().path for dataset in cells]\n",
    "    dataset_lookup = {cell.uid: idx for idx, cell in enumerate(cells)}\n",
    "    labels = list(dataset_lookup.values())\n",
    "    results = featurizer.process(\n",
    "        extraction_dir=paths[0], labels=labels[0], return_results=True\n",
    "    )\n",
    "    results[\"class\"] = idx\n",
    "    condition_lookup[condition_ul.name] = 1\n",
    "    if features is None:\n",
    "        features = results\n",
    "    else:\n",
    "        features = pd.concat([features, results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7740618b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m→\u001b[0m found artifact with same hash: Artifact(uid='OZUxfqXUi6YtFrVW0000', is_latest=True, description='featurized single-cell images', suffix='.parquet', kind='dataset', otype='DataFrame', size=67768, hash='Xm_6eKDzVstPMARccKPHzg', space_id=1, storage_id=1, run_id=127, created_by_id=3, created_at=2025-02-24 15:23:27 UTC); to track this artifact as an input, use: ln.Artifact.get()\n"
     ]
    }
   ],
   "source": [
    "artifact = ln.Artifact.from_df(\n",
    "    features, description=\"featurized single-cell images\"\n",
    ").save()\n",
    "artifact.cell_lines.add(bt.CellLine.get(name=\"U2OS\"))\n",
    "\n",
    "# annotate metadata\n",
    "artifact.features.add_values(\n",
    "    {\n",
    "        \"study\": \"autophagy imaging\",\n",
    "        \"artifact type\": \"single-cell image featurization results\",\n",
    "        \"genotype\": \"WT\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5355c38b",
   "metadata": {},
   "source": [
    "We repeat this process for KO cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5878d618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... synchronizing ws65rSiY0he9SSve0000.h5: 100.0%\n",
      "... synchronizing zJZEvnfApxBWCJzZ0000.h5: 100.0%\n",
      "... synchronizing jP8M4lTmCX4A3xCs0000.h5: 100.0%\n",
      "... synchronizing DQQX6jIYqsxZv9ec0000.h5: 100.0%\n",
      "... synchronizing cYLJWBZoUyQxFwii0000.h5: 100.0%\n",
      "... synchronizing 9CMfEX06h1RJrjPP0000.h5: 100.0%\n",
      "... synchronizing Kt9FXnHBQeZ8F0mj0000.h5: 100.0%\n",
      "... synchronizing P6r2aqhFZomH93uJ0000.h5: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Train on wildtype cells\n",
    "ko_cells_afs = sc_datasets.filter(ulabels__name=\"EI24KO\")\n",
    "\n",
    "# we have two different conditions which will be the two classes that our classifier should be able to tell apart\n",
    "condition_uls = [\n",
    "    ln.ULabel.get(name=stimulation_name)\n",
    "    for stimulation_name in set(\n",
    "        af.features.get_values()[\"stimulation\"] for af in ko_cells_afs\n",
    "    )\n",
    "]\n",
    "\n",
    "# we will store the calculated features in a dictionary for each condition\n",
    "condition_lookup = {}\n",
    "features_ko = None\n",
    "for idx, condition_ul in enumerate(condition_uls):\n",
    "    cells = ko_cells_afs.filter(ulabels=condition_ul)\n",
    "    paths = [dataset.load().path for dataset in cells]\n",
    "    dataset_lookup = {cell.uid: idx for idx, cell in enumerate(cells)}\n",
    "    labels = list(dataset_lookup.values())\n",
    "    results = featurizer.process(\n",
    "        extraction_dir=paths[0], labels=labels[0], return_results=True\n",
    "    )\n",
    "    results[\"class\"] = idx\n",
    "    condition_lookup[condition_ul.name] = 1\n",
    "    if features_ko is None:\n",
    "        features_ko = results\n",
    "    else:\n",
    "        features_ko = pd.concat([features_ko, results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88ad588b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... uploading vqgUwzZxmlVMNRj00000.parquet: 100.0%\n"
     ]
    }
   ],
   "source": [
    "artifact = ln.Artifact.from_df(\n",
    "    features_ko, description=\"featurized single-cell images\"\n",
    ").save()\n",
    "artifact.cell_lines.add(bt.CellLine.filter(name=\"U2OS\").one())\n",
    "\n",
    "# annotate with required metadata\n",
    "artifact.features.add_values(\n",
    "    {\n",
    "        \"study\": \"autophagy imaging\",\n",
    "        \"artifact type\": \"single-cell image featurization results\",\n",
    "        \"genotype\": \"EI24KO\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f625fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m•\u001b[0m please hit CTRL + s to save the notebook in your editor  \u001b[92m✓\u001b[0m\n",
      "\u001b[93m!\u001b[0m cells [(2, None), (None, 14), (15, 17)] were not run consecutively\n",
      "\u001b[92m→\u001b[0m finished Run('aWmCDdv4') after 44m at 2025-02-24 15:47:26 UTC\n",
      "\u001b[92m→\u001b[0m go to: https://lamin.ai/scportrait/examples/transform/ujI2BcWc8AA60000\n",
      "\u001b[92m→\u001b[0m to update your notebook from the CLI, run: lamin save /home/lukas/code/lamin-usecases/docs/imaging3.ipynb\n"
     ]
    }
   ],
   "source": [
    "ln.finish()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "lamindb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
