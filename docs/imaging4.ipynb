{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "![imaging4/4](https://img.shields.io/badge/imaging4/4-lightgrey)\n",
    "[![Jupyter Notebook](https://img.shields.io/badge/Source%20on%20GitHub-orange)](https://github.com/laminlabs/lamin-usecases/blob/main/docs/imaging4.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Train a machine learning model to identify autophagy-positive cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "The goal of this notebook is to train a ML model to distininguish between autophagy-positive and autophagy-negative cells based on pre-calculated image features.\n",
    "\n",
    "We have defined our classes as follows:\n",
    "\n",
    "``Class 0`` : unstimulated WT cells  \n",
    "``Class 1`` : 14h Torin-1 stimulated WT cells  \n",
    "\n",
    "After training and evaluating our model we want to see how cells without a functional *EI24* gene (``EI24KO`` cells) compare to ``WT`` cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lamindb as ln\n",
    "import matplotlib.pyplot as plt\n",
    "import scportrait\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from anndata import concat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "ln.track()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_cells(dataframe: pd.DataFrame):\n",
    "    \"\"\"Extract and concatenate single-cell data for cells specified in the input dataframe.\"\"\"\n",
    "    sc_data = None\n",
    "    for uid in dataframe.dataset.unique():\n",
    "        _selected_cells = dataframe[dataframe.dataset == uid].copy()\n",
    "        _sc_data = scportrait.io.read_h5sc(ln.Artifact.get(uid).cache())\n",
    "        _sc_data = _sc_data[\n",
    "            _sc_data.obs.cell_id.isin(_selected_cells.cell_id.values)\n",
    "        ].copy()\n",
    "        _sc_data.obs[\"score\"] = _selected_cells.prob_class1.values\n",
    "\n",
    "        if sc_data is None:\n",
    "            sc_data = _sc_data\n",
    "        else:\n",
    "            sc_data = concat([sc_data, _sc_data], uns_merge=\"first\", index_unique=\"-\")\n",
    "            sc_data.obs.reset_index(inplace=True, drop=True)\n",
    "            sc_data.obs.index = sc_data.obs.index.values.astype(str)\n",
    "    return sc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for our RandomForest Classifier\n",
    "ln.Param(name=\"random_state\", dtype=\"int\").save()\n",
    "ln.Param(name=\"n_estimators\", dtype=\"int\").save()\n",
    "ln.Param(name=\"max_depth\", dtype=\"int\").save()\n",
    "ln.Param(name=\"min_samples_split\", dtype=\"int\").save()\n",
    "ln.Param(name=\"min_samples_leaf\", dtype=\"int\").save()\n",
    "ln.Param(name=\"max_features\", dtype=\"str\").save()\n",
    "ln.Param(name=\"criterion\", dtype=\"str\").save()\n",
    "ln.Param(name=\"bootstrap\", dtype=\"bool\").save()\n",
    "\n",
    "# Define parameter values\n",
    "rfc_params = {\n",
    "    \"random_state\": 42,\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"criterion\": \"gini\",\n",
    "    \"bootstrap\": True,\n",
    "}\n",
    "\n",
    "ln.track(params=rfc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = ln.ULabel.using(\"scportrait/examples\").get(name=\"autophagy imaging\")\n",
    "\n",
    "sc_datasets = (\n",
    "    ln.Artifact.using(\"scportrait/examples\")\n",
    "    .filter(ulabels=study)\n",
    "    .filter(ulabels__name=\"scportrait single-cell images\")\n",
    ")\n",
    "featurized_datasets = (\n",
    "    ln.Artifact.using(\"scportrait/examples\")\n",
    "    .filter(ulabels=study)\n",
    "    .filter(ulabels__name=\"single-cell image featurization results\")\n",
    ")\n",
    "\n",
    "class_lookup = {0: \"untreated\", 1: \"14h Torin-1\"}\n",
    "label_lookup = {v: k for k, v in class_lookup.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "First, lets look at some example images from our two classes. As we can see the cells look very distinct to one another. Hopefully our ML model will be able to seperate them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get example images for positive and negative autophagy\n",
    "num_rows, num_cols = 4, 4\n",
    "n_cells = num_rows * num_cols\n",
    "channel_of_interest = 4  # LC3B channel a key autophagosome marker\n",
    "\n",
    "autophagy_positive_example = scportrait.io.read_h5sc(\n",
    "    sc_datasets.filter(ulabels__name=\"WT\")\n",
    "    .filter(ulabels__name=\"14h Torin-1\")[0]\n",
    "    .cache()\n",
    ")\n",
    "autophagy_negative_example = scportrait.io.read_h5sc(\n",
    "    sc_datasets.filter(ulabels__name=\"WT\").filter(ulabels__name=\"untreated\")[0].cache()\n",
    ")\n",
    "\n",
    "# create a figure with two panels for negative and postive examples\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 7))\n",
    "scportrait.pl.cell_grid_single_channel(\n",
    "    autophagy_negative_example,\n",
    "    select_channel=channel_of_interest,\n",
    "    ax=axes[0],\n",
    "    title=\"Autophagy negative cells (LC3B distribution)\",\n",
    "    show_fig=False,\n",
    ")\n",
    "scportrait.pl.cell_grid_single_channel(\n",
    "    autophagy_positive_example,\n",
    "    select_channel=channel_of_interest,\n",
    "    ax=axes[1],\n",
    "    title=\"Autophagy postive cells (LC3B distribution)\",\n",
    "    show_fig=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Train ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "wt_cells_afs = (\n",
    "    featurized_datasets.filter(ulabels__name=\"WT\", is_latest=True).distinct().one()\n",
    ")\n",
    "features_wt = wt_cells_afs.load()\n",
    "\n",
    "ko_cells_afs = (\n",
    "    featurized_datasets.filter(ulabels__name=\"EI24KO\", is_latest=True).distinct().one()\n",
    ")\n",
    "features_ko = ko_cells_afs.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing\n",
    "data_train, data_test = train_test_split(features_wt, test_size=0.4, random_state=42)\n",
    "\n",
    "# prepare data for model training by removing columns we don't want to train on\n",
    "_data_train = data_train.drop(columns=[\"dataset\", \"cell_id\"])\n",
    "_data_train = _data_train.drop(\n",
    "    columns=[col for col in data_train.columns if \"mCherry\" in col]\n",
    ")  # subset to only include features from our channel of interest\n",
    "\n",
    "_data_test = data_test.drop(columns=[\"dataset\", \"cell_id\"])\n",
    "_data_test = _data_test.drop(\n",
    "    columns=[col for col in data_test.columns if \"mCherry\" in col]\n",
    ")  # subset to only include features from our channel of interest\n",
    "\n",
    "# Separate features and target\n",
    "X_train = _data_train.drop(\"class\", axis=1)\n",
    "y_train = _data_train[\"class\"]\n",
    "\n",
    "X_test = _data_test.drop(\"class\", axis=1)\n",
    "y_test = _data_test[\"class\"]\n",
    "\n",
    "# Train model\n",
    "clf = RandomForestClassifier(**rfc_params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "y_scores = clf.predict_proba(X_test)\n",
    "\n",
    "data_test[\"predicted_class\"] = y_pred\n",
    "data_test[\"prob_class1\"] = y_scores[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "labels = np.unique(y_test)\n",
    "labels = [class_lookup[label] for label in labels]\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_scores[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the confusion matrix and ROC Curve\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "sns.heatmap(\n",
    "    cm_normalized,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels,\n",
    "    ax=axes[1],\n",
    "    cbar=False,\n",
    ")\n",
    "axes[1].set_xlabel(\"Predicted Label\")\n",
    "axes[1].set_ylabel(\"True Label\")\n",
    "axes[1].set_title(\"Confusion Matrix [% of true label]\")\n",
    "\n",
    "axes[0].plot(fpr, tpr, color=\"blue\", lw=2, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
    "axes[0].plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\")  # Diagonal line\n",
    "axes[0].set_xlim([0.0, 1.0])\n",
    "axes[0].set_ylim([0.0, 1.0])\n",
    "axes[0].set_xlabel(\"False Positive Rate\")\n",
    "axes[0].set_ylabel(\"True Positive Rate\")\n",
    "axes[0].set_title(\"ROC Curve\")\n",
    "axes[0].legend(loc=\"lower right\", frameon=False)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Considering that it was only trained on very few input images, our classifier performs well with an AUC of 0.77. This is already much better than a random classifier which we would expect to have an AUC of 0.5.\n",
    "\n",
    "However, since the AUC is < 1, our model is still appears to make some mistakes. We can further investigate this through a confusion matrix. Our classifier is performing well at recognizing autophagy negative cells, correctly identifying 92% of the examples in our dataset. Unfortunately, the classifier is not yet very good at correctly identifying autophagy-postive cells. Less than 50% of these examples are classified correctly.\n",
    "\n",
    "Let's visualize some of the cells from each class to see if we can gain some insights into what our model is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some example cells with classification scores from the test dataset\n",
    "num_rows, num_cols = 3, 3\n",
    "n_cells = num_rows * num_cols\n",
    "channel_of_interest = 4  # LC3B channel a key autophagosome marker\n",
    "\n",
    "# annotate dataset with TP, TN, FN, FP\n",
    "data_test[\"FP\"] = (data_test[\"class\"] == 0) & (data_test[\"predicted_class\"] == 1)\n",
    "data_test[\"FN\"] = (data_test[\"class\"] == 1) & (data_test[\"predicted_class\"] == 0)\n",
    "data_test[\"TP\"] = (data_test[\"class\"] == 1) & (data_test[\"predicted_class\"] == 1)\n",
    "data_test[\"TN\"] = (data_test[\"class\"] == 0) & (data_test[\"predicted_class\"] == 0)\n",
    "\n",
    "# get example cells for each class\n",
    "cells_TP = (\n",
    "    data_test[data_test.TP].sort_values(\"prob_class1\", ascending=False).head(n_cells)\n",
    ")\n",
    "cells_TN = (\n",
    "    data_test[data_test.TN].sort_values(\"prob_class1\", ascending=False).tail(n_cells)\n",
    ")\n",
    "cells_FN = (\n",
    "    data_test[data_test.FN].sort_values(\"prob_class1\", ascending=False).tail(n_cells)\n",
    ")\n",
    "cells_FP = (\n",
    "    data_test[data_test.FP].sort_values(\"prob_class1\", ascending=False).head(n_cells)\n",
    ")\n",
    "\n",
    "cell_sets = {\n",
    "    \"TP\": _get_cells(cells_TP),\n",
    "    \"TN\": _get_cells(cells_TN),\n",
    "    \"FN\": _get_cells(cells_FN),\n",
    "    \"FP\": _get_cells(cells_FP),\n",
    "}\n",
    "\n",
    "# make the plot\n",
    "n_panel_rows = 2\n",
    "n_panel_cols = 2\n",
    "fig, axes = plt.subplots(nrows=n_panel_rows, ncols=n_panel_cols, figsize=(13, 13))\n",
    "\n",
    "for j in range(n_panel_rows):\n",
    "    for i in range(n_panel_cols):\n",
    "        ax = axes[j, i]\n",
    "        title, cells = cell_sets.popitem()\n",
    "        scportrait.pl.cell_grid_single_channel(\n",
    "            cells,\n",
    "            cell_ids=cells.obs.cell_id,\n",
    "            cell_labels=cells.obs.score.round(2).values,\n",
    "            select_channel=channel_of_interest,\n",
    "            ax=ax,\n",
    "            title=f\"{title} with Prob(stimulated)\",\n",
    "            show_fig=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Looking at the False Positives (i.e. cells that look stimulated despite not having been stimulated) we can see two different types of cells:\n",
    "1. Very small cells that do not show any visible autophagosomes\n",
    "2. Larger cells that clearly show some autophagosomes\n",
    "\n",
    "The type 1 cells look like they are the result of our model making mistakes, but the type 2 cells look much more similar to TP cells than TN cells.\n",
    "Based on literature, we know that cells can under go spontaneous autophagy even in the absence of Torin-1, for example, as a result of nutrient scarcity.\n",
    "Since our class labelling is just based on cells having not been treated with Torin-1, we would be annotating these cells incorrectly.\n",
    "In these cases our model does not make a mistake, but has in fact uncovered mislabelled examples in the dataset.\n",
    "\n",
    "Looking at the False Negatives (i.e. cells that the model identifies as having been unstimulated despite having been stimulated) the cells appear homogenous and look more comparable to the True Positive Population.\n",
    "So in this case it seems our model is making a mistake. \n",
    "\n",
    "Before applying this model in a biological context, we would therefore probably need to invest some more time and effort into improving it! \n",
    "\n",
    "We could for example:\n",
    "1. Train our model on more input data to make it more robust\n",
    "2. Perform a pre-screening of our training data to ensure we remove any incorrectly labelled cells\n",
    "3. Improve the image features we are training our model on to better reflect the biology we are interested in\n",
    "\n",
    "If you are interested in finding out more you can check out the [original paper](https://www.biorxiv.org/content/10.1101/2023.06.01.542416v1) where the authors trained a deep learning model to classify these cells with a much higher accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Investigate the *EI24* KO cells\n",
    "\n",
    "Now lets take a look at the EI24-deficient cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ko = features_ko.drop(columns=[\"dataset\", \"cell_id\"])\n",
    "data_ko = data_ko.drop(columns=[x for x in data_ko.columns if \"mCherry\" in x])\n",
    "X_ko = data_ko.drop(\"class\", axis=1)\n",
    "y_true = data_ko[\"class\"]\n",
    "predictions_ko = clf.predict(X_ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute confusion matrix\n",
    "cm = confusion_matrix(y_true, predictions_ko)\n",
    "cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "labels = np.unique(y_test)\n",
    "labels = [class_lookup[label] for label in labels]\n",
    "\n",
    "# Plot the confusion matrix and ROC Curve\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(4, 2))\n",
    "sns.heatmap(\n",
    "    cm_normalized,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels,\n",
    "    ax=axes,\n",
    "    cbar=False,\n",
    ")\n",
    "axes.set_xlabel(\"Predicted Label\")\n",
    "axes.set_ylabel(\"True Label\")\n",
    "axes.set_title(\"Confusion Matrix [% of true label]\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Interestingly, our model classifies a high percentage of stimulated *EI24*-KO cells as being unstimulated. Lets take a look at the images again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare WT And EI24KO cells\n",
    "num_rows, num_cols = 4, 4\n",
    "n_cells = num_rows * num_cols\n",
    "channel_of_interest = 4  # LC3B channel a key autophagosome marker\n",
    "\n",
    "EI24_KO_stimulated = scportrait.io.read_h5sc(\n",
    "    sc_datasets.filter(ulabels__name=\"EI24KO\")\n",
    "    .filter(ulabels__name=\"14h Torin-1\")[0]\n",
    "    .cache()\n",
    ")\n",
    "EI24_KO_unstimulated = scportrait.io.read_h5sc(\n",
    "    sc_datasets.filter(ulabels__name=\"EI24KO\")\n",
    "    .filter(ulabels__name=\"untreated\")[0]\n",
    "    .cache()\n",
    ")\n",
    "\n",
    "# create a figure with two panels for negative and postive examples\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 12))\n",
    "scportrait.pl.cell_grid_single_channel(\n",
    "    autophagy_negative_example,\n",
    "    select_channel=channel_of_interest,\n",
    "    ax=axes[0, 0],\n",
    "    title=\"WT autophagy negative cells\",\n",
    "    show_fig=False,\n",
    ")\n",
    "scportrait.pl.cell_grid_single_channel(\n",
    "    autophagy_positive_example,\n",
    "    select_channel=channel_of_interest,\n",
    "    ax=axes[0, 1],\n",
    "    title=\"WT autophagy postive cells\",\n",
    "    show_fig=False,\n",
    ")\n",
    "scportrait.pl.cell_grid_single_channel(\n",
    "    EI24_KO_unstimulated,\n",
    "    select_channel=channel_of_interest,\n",
    "    ax=axes[1, 0],\n",
    "    title=\"EI24KO unstimulated cells\",\n",
    "    show_fig=False,\n",
    ")\n",
    "scportrait.pl.cell_grid_single_channel(\n",
    "    EI24_KO_stimulated,\n",
    "    select_channel=channel_of_interest,\n",
    "    ax=axes[1, 1],\n",
    "    title=\"EI24KO stimulated cells\",\n",
    "    show_fig=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "The *EI24* KO cells have fewer LC3 puncta, and seem to show a defect in the formation of autophagosomes. Even when stimulated, *EI24* KO cells look comparable to unstimated cells. In this instance, out model appears to correctly identify the biological effect of a deficiency in the *EI24* gene."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Trace cells back to see them in their original context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "As image analysis advances, obtaining the full context of a small section of the original image is often essential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a random cell from the WT  dataset\n",
    "cell = features_wt.sample(1, random_state=42)\n",
    "dataset = cell[\"dataset\"].values[0]\n",
    "cell_id = cell[\"cell_id\"].values[0]\n",
    "\n",
    "# get SpatialData object and single-cell image dataset\n",
    "sdata = (\n",
    "    ln.Artifact.using(\"scportrait/examples\")\n",
    "    .get(\n",
    "        key=ln.Artifact.using(\"scportrait/examples\")\n",
    "        .get(dataset)\n",
    "        .key.replace(\"single_cell_data.h5ad\", \"spatialdata.zarr\")\n",
    "    )\n",
    "    .load()\n",
    ")\n",
    "single_cell_images = scportrait.io.read_h5sc(ln.Artifact.get(dataset).cache())\n",
    "\n",
    "# lookup location of cell of interest\n",
    "x, y = sdata[\"centers_seg_all_nucleus\"].compute().loc[cell_id, :]\n",
    "\n",
    "# plot single-cell images and spatial context\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 3.5))\n",
    "scportrait.pl.cell_grid_multi_channel(\n",
    "    single_cell_images, cell_ids=cell_id, axs=axs[0], show_fig=False\n",
    ")\n",
    "scportrait.pl.plot_segmentation_mask(\n",
    "    sdata,\n",
    "    masks=[\"seg_all_nucleus\", \"seg_all_cytosol\"],\n",
    "    select_region=(x, y),\n",
    "    max_width=100,\n",
    "    axs=axs[1],\n",
    "    show_fig=False,\n",
    ")\n",
    "axs[1].scatter(\n",
    "    x,\n",
    "    y,\n",
    "    color=\"red\",\n",
    "    s=200,\n",
    ")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!rm -rf test-imaging\n",
    "!lamin delete --force test-imaging"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "lamindb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
