{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![scrna6/6](https://img.shields.io/badge/scrna6/6-lightgrey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate datasets to a single array store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebooks, we've seen how to incrementally create a collection of scRNA-seq datasets and train models on it.\n",
    "\n",
    "Sometimes we want to concatenate all datasets into one big array to speed up ad-hoc queries for slices for arbitrary metadata.\n",
    "\n",
    "This is also what CELLxGENE does to create Census: a number of `.h5ad` files are concatenated to give rise to a single `tiledbsoma` array store ({doc}`docs:cellxgene`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import lamindb as ln\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import tiledbsoma.io\n",
    "from functools import reduce\n",
    "\n",
    "ln.track(\"oJN8WmVrxI8m0000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the collection of `h5ad` files that we'd like to concatenate into a single array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "collection = ln.Collection.get(key=\"scrna/collection1\", version=\"2\")\n",
    "collection.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the AnnData objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To concatenate the `AnnData` objects into a single `tiledbsoma.Experiment`, they need to have the same `.var` and `.obs` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# load a number of AnnData objects that's small enough to fit into memory\n",
    "adatas = [artifact.load() for artifact in collection.ordered_artifacts]\n",
    "\n",
    "# compute the intersection of columns for these objects\n",
    "var_columns = reduce(\n",
    "    pd.Index.intersection, [adata.var.columns for adata in adatas]\n",
    ")  # this only affects metadata columns of features (say, gene annotations)\n",
    "var_raw_columns = reduce(\n",
    "    pd.Index.intersection, [adata.raw.var.columns for adata in adatas]\n",
    ")\n",
    "obs_columns = reduce(\n",
    "    pd.Index.intersection, [adata.obs.columns for adata in adatas]\n",
    ")  # this actually subsets features (dataset dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the `AnnData` objects for concatenation. Prepare id fields, sanitize `index` names, intersect columns, drop `.obsp`, `.uns` and columns that aren't part of the intersection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "for i, adata in enumerate(adatas):\n",
    "    del adata.obsp  # not supported by tiledbsoma\n",
    "    del adata.uns  # not supported by tiledbsoma\n",
    "\n",
    "    adata.obs = adata.obs.filter(obs_columns)  # filter columns to intersection\n",
    "    adata.obs[\"obs_id\"] = (\n",
    "        adata.obs.index\n",
    "    )  # prepare a column for tiledbsoma to use as an index\n",
    "    adata.obs[\"dataset\"] = i\n",
    "    adata.obs.index.name = None\n",
    "\n",
    "    adata.var = adata.var.filter(var_columns)  # filter columns to intersection\n",
    "    adata.var[\"var_id\"] = adata.var.index\n",
    "    adata.var.index.name = None\n",
    "\n",
    "    drop_raw_var_columns = adata.raw.var.columns.difference(var_raw_columns)\n",
    "    adata.raw.var.drop(columns=drop_raw_var_columns, inplace=True)\n",
    "    adata.raw.var[\"var_id\"] = adata.raw.var.index\n",
    "    adata.raw.var.index.name = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the array store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the `AnnData` objects in one array store referenced by an `Artifact`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "soma_artifact = ln.integrations.save_tiledbsoma_experiment(\n",
    "    adatas,\n",
    "    description=\"tiledbsoma experiment\",\n",
    "    measurement_name=\"RNA\",\n",
    "    obs_id_name=\"obs_id\",\n",
    "    var_id_name=\"var_id\",\n",
    "    append_obsm_varm=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "\n",
    "Provenance is tracked by writing the current `run.uid` to `tiledbsoma.Experiment.obs` as `lamin_run_uid`.\n",
    "\n",
    "If you know `tiledbsoma` API, then note that {func}`~docs:lamindb.integrations.save_tiledbsoma_experiment` abstracts over both `tiledbsoma.io.register_anndatas` and `tiledbsoma.io.from_anndata`.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the array store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we query the `obs` from the array store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "with soma_artifact.open() as soma_store:\n",
    "    obs = soma_store[\"obs\"]\n",
    "    var = soma_store[\"ms\"][\"RNA\"][\"var\"]\n",
    "\n",
    "    obs_columns_store = obs.schema.names\n",
    "    var_columns_store = var.schema.names\n",
    "\n",
    "    obs_store_df = obs.read().concat().to_pandas()\n",
    "\n",
    "    display(obs_store_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append to the array store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a new `AnnData` object to be appended to the store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.core.datasets.anndata_with_obs().write_h5ad(\"adata_to_append.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "!lamin save adata_to_append.h5ad --description \"adata to append\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "adata = ln.Artifact.filter(description=\"adata to append\").one().load()\n",
    "\n",
    "adata.obs_names_make_unique()\n",
    "adata.var_names_make_unique()\n",
    "\n",
    "adata.obs[\"obs_id\"] = adata.obs.index\n",
    "adata.var[\"var_id\"] = adata.var.index\n",
    "\n",
    "adata.obs[\"dataset\"] = obs_store_df[\"dataset\"].max()\n",
    "\n",
    "obs_columns_same = [\n",
    "    obs_col for obs_col in adata.obs.columns if obs_col in obs_columns_store\n",
    "]\n",
    "adata.obs = adata.obs[obs_columns_same]\n",
    "\n",
    "var_columns_same = [\n",
    "    var_col for var_col in adata.var.columns if var_col in var_columns_store\n",
    "]\n",
    "adata.var = adata.var[var_columns_same]\n",
    "\n",
    "adata.write_h5ad(\"adata_to_append.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the `AnnData` object from disk by revising `soma_artifact`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "soma_artifact = ln.integrations.save_tiledbsoma_experiment(\n",
    "    [\"adata_to_append.h5ad\"],\n",
    "    revises=soma_artifact,\n",
    "    measurement_name=\"RNA\",\n",
    "    obs_id_name=\"obs_id\",\n",
    "    var_id_name=\"var_id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the array store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a new embedding to the existing array store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# read the data matrix\n",
    "with soma_artifact.open() as soma_store:\n",
    "    ms_rna = soma_store[\"ms\"][\"RNA\"]\n",
    "    n_obs = len(soma_store[\"obs\"])\n",
    "    n_var = len(ms_rna[\"var\"])\n",
    "    X = ms_rna[\"X\"][\"data\"].read().coos((n_obs, n_var)).concat().to_scipy().tocsr()\n",
    "\n",
    "# calculate PCA embedding from the queried `X`\n",
    "pca_array = sc.pp.pca(X, n_comps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the array store in write mode and add PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "with soma_artifact.open(mode=\"w\") as soma_store:\n",
    "    tiledbsoma.io.add_matrix_to_collection(\n",
    "        exp=soma_store,\n",
    "        measurement_name=\"RNA\",\n",
    "        collection_name=\"obsm\",\n",
    "        matrix_name=\"pca\",\n",
    "        matrix_data=pca_array,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See array store mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the append-to and update operations, the data in the array store was changed. LaminDB automatically tracks these revisions recording the number of objects, hashes, and provenance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "soma_artifact.versions.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View lineage of the array store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the generating flow of the array store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_artifact.view_lineage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "\n",
    "For the underlying API, see [the tiledbsoma documentation](https://tiledbsoma.readthedocs.io/en/latest/notebooks/tutorial_soma_append_mode.html).\n",
    "\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
