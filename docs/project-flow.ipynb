{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Jupyter Notebook](https://img.shields.io/badge/Jupyter%20Notebook-orange)](https://github.com/laminlabs/lamin-usecases/blob/main/docs/birds-eye.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project flow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LaminDB enables to model data flow on the entire-project level.\n",
    "\n",
    "Here, we walk through exemplified app uploads, pipelines & notebooks following [Schmidt _et al._, 2022](https://pubmed.ncbi.nlm.nih.gov/35113687/): A genome-wide CRISPR screen reading out a phenotypic endpoint on T cells is paired with scRNA-seq to generate insights into IFN-Î³ production.\n",
    "\n",
    "These insights get linked back to the original data through the steps taken in the project to provide context for interpretation & future decision making.\n",
    "\n",
    ":::{dropdown} More specifically: Why should I care about data flow?\n",
    "\n",
    "Data flow tracks data sources & transformations to trace biological insights, verify experimental outcomes, meet regulatory standards, increase the robustness of research and optimize the feedback loop of team-wide learning iterations.\n",
    "\n",
    "While tracking data flow is easier when it's governed by deterministic pipelines, it becomes hard when it's governed by interactive human-driven analyses.\n",
    "\n",
    "LaminDB interfaces workflow mangers for the former and embraces the latter.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init a test instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "!lamin init --storage ./mydata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import lamindb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lamindb as ln\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we walk through exemplified steps. The full notebooks are in [this repository](https://github.com/laminlabs/rnd-demo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### App upload of phenotypic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register data through app upload from wetlab by `testuser1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.setup.login(\"testuser1\")\n",
    "transform = ln.Transform(name=\"Upload GWS CRISPRa result\", type=\"app\")\n",
    "ln.track(transform)\n",
    "output_path = ln.dev.datasets.schmidt22_crispra_gws_IFNG(ln.settings.storage)\n",
    "output_file = ln.File(output_path, description=\"Raw data of schmidt22 crispra GWS\")\n",
    "output_file.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hit identification in notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access, transform & register data in drylab by `testuser2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.setup.login(\"testuser2\")\n",
    "transform = ln.Transform(name=\"GWS CRIPSRa analysis\", type=\"notebook\")\n",
    "ln.track(transform)\n",
    "# access\n",
    "input_file = ln.File.filter(key=\"schmidt22-crispra-gws-IFNG.csv\").one()\n",
    "# identify hits\n",
    "input_df = input_file.load().set_index(\"id\")\n",
    "output_df = df[df[\"pos|fdr\"] < 0.01].copy()\n",
    "# register hits in output file\n",
    "ln.File(output_df, description=\"hits from schmidt22 crispra GWS\").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect data flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = ln.File.filter(description=\"hits from schmidt22 crispra GWS\").one()\n",
    "file.view_lineage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequencer upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload files from sequencer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ln.setup.login(\"testuser1\")\n",
    "ln.track(ln.Transform(name=\"Chromium 10x upload\", type=\"pipeline\"))\n",
    "# register output files of upload\n",
    "upload_dir = ln.dev.datasets.dir_scrnaseq_cellranger(\n",
    "    \"perturbseq\", basedir=ln.settings.storage, output_only=False\n",
    ")\n",
    "ln.File(upload_dir.parent / \"fastq/perturbseq_R1_001.fastq.gz\").save()\n",
    "ln.File(upload_dir.parent / \"fastq/perturbseq_R2_001.fastq.gz\").save()\n",
    "ln.setup.login(\"testuser2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track scRNA-seq bioinformatics pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process uploaded files using a script or workflow manager: {doc}`pipelines` and obtain 3 output files in a directory `filtered_feature_bc_matrix/`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "transform = ln.Transform(name=\"Cell Ranger\", version=\"7.2.0\", type=\"pipeline\")\n",
    "ln.track(transform)\n",
    "# access uploaded files as inputs for the pipeline\n",
    "input_files = ln.File.filter(key__startswith=\"fastq/perturbseq\").all()\n",
    "input_paths = [file.stage() for file in files]\n",
    "# register output files\n",
    "output_files = ln.File.from_dir(\"./mydata/perturbseq/filtered_feature_bc_matrix/\")\n",
    "ln.save(output_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect data lineage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files[0].view_lineage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-process Cell Ranger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "transform = ln.Transform(name=\"Postprocess Cell Ranger\", version=\"2.0\", type=\"pipeline\")\n",
    "ln.track(transform)\n",
    "input_files = [f.stage() for f in output_files]\n",
    "output_path = ln.dev.datasets.schmidt22_perturbseq(basedir=ln.settings.storage)\n",
    "output_file = ln.File(output_path, description=\"perturbseq counts\")\n",
    "output_file.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate scRNA-seq & CRISPR screen results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate data in a notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "transform = ln.Transform(\n",
    "    name=\"Perform single cell analysis, integrate with CRISPRa screen\",\n",
    "    type=\"notebook\",\n",
    ")\n",
    "ln.track(transform)\n",
    "\n",
    "file_ps = ln.File.filter(description__icontains=\"perturbseq\").one()\n",
    "adata = file_ps.load()\n",
    "screen_hits = file_hits.load()\n",
    "\n",
    "import scanpy as sc\n",
    "\n",
    "sc.tl.score_genes(adata, adata.var_names.intersection(screen_hits.index).tolist())\n",
    "filesuffix = \"_fig1_score-wgs-hits.png\"\n",
    "sc.pl.umap(adata, color=\"score\", show=False, save=filesuffix)\n",
    "filepath = f\"figures/umap{filesuffix}\"\n",
    "file = ln.File(filepath, key=filepath)\n",
    "file.save()\n",
    "filesuffix = \"fig2_score-wgs-hits-per-cluster.png\"\n",
    "sc.pl.matrixplot(\n",
    "    adata, groupby=\"cluster_name\", var_names=[\"score\"], show=False, save=filesuffix\n",
    ")\n",
    "filepath = f\"figures/matrixplot_{filesuffix}\"\n",
    "file = ln.File(filepath, key=filepath)\n",
    "file.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load one of the plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.track()\n",
    "file = ln.File.filter(key__contains=\"figures/matrixplot\").one()\n",
    "file.stage()\n",
    "display(Image(filename=file.path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the image file is tracked as an input of the current notebook. The input is highlighted, the notebook follows at the bottom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.view_lineage()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can also look at the sequence of transforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = ln.Transform.search(\"Bird's eye view\", return_queryset=True).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform.parents.df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform.view_parents()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand runs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tracked pipeline and notebook runs through {class}`~docs:lamindb.dev.run_context`, which stores a {class}`~docs:lamindb.Transform` and a {class}`~docs:lamindb.Run` record as a global context.\n",
    "\n",
    "{class}`~lamindb.File` objects are the inputs and outputs of runs. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} What if I don't want a global context?\n",
    "\n",
    "Sometimes, we don't want to create a global run context but manually pass a run when creating a file:\n",
    "```python\n",
    "run = ln.Run(transform=transform)\n",
    "ln.File(filepath, run=run)\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{dropdown} When does a file appear as a run input?\n",
    "\n",
    "When accessing a file via `stage()`, `load()` or `backed()`, two things happen:\n",
    "\n",
    "1. The current run gets added to `file.input_of`\n",
    "2. The transform of that file gets added as a parent of the current transform\n",
    "\n",
    "You can then switch off auto-tracking of run inputs if you set `ln.settings.track_run_inputs = False`: {doc}`docs:faq/track-run-inputs`\n",
    "\n",
    "You can also track run inputs on a case by case basis via `is_run_input=True`, e.g., here:\n",
    "```python\n",
    "file.load(is_run_input=True)\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query by provenance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can query or search for the notebook that created the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = ln.Transform.search(\"GWS CRIPSRa analysis\", return_queryset=True).first()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then find all the files created by that notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.File.filter(transform=transform).df()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which transform ingested a given file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = ln.File.filter().first()\n",
    "file.transform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And which user?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.created_by"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which transforms were created by a given user?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = ln.User.lookup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.Transform.filter(created_by=users.testuser2).df()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which notebooks were created by a given user?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.Transform.filter(created_by=users.testuser2, type=\"notebook\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view all recent additions to the entire database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "ln.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!lamin login testuser1\n",
    "!lamin delete --force mydata\n",
    "!rm -r ./mydata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "nbproject": {
   "id": "1LCd8kco9lZU",
   "parent": null,
   "pypackage": null,
   "time_init": "2023-01-23T13:53:15.227959+00:00",
   "user_handle": "testuser1",
   "user_id": "DzTjkKse",
   "user_name": "Test User1",
   "version": "0"
  },
  "vscode": {
   "interpreter": {
    "hash": "61b4062b24dfb1010f420dad5aa3bd73a4d2af47d0ec44eafec465a35a9d7239"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
